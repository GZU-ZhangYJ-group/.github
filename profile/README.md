## è¿™é‡Œæ˜¯è´µå·å¤§å­¦å¼ æ°¸å†›è€å¸ˆå›¢é˜ŸğŸ‘‹

### å…³äºæˆ‘ä»¬

- å¯¼å¸ˆä¸»é¡µ: http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm

- DBLP: https://dblp.org/pid/43/5828-7.html

- è”ç³»é‚®ç®±ï¼š[![Gmail Badge](https://img.shields.io/badge/-zyj6667@126.com-c14438?style=flat-square&logo=Gmail&logoColor=white&link=mailto:zyj6667@126.com)](mailto:zyj6667@126.com)

- æ¯•ä¸šç”Ÿå»å‘ï¼šåœ¨é¦™æ¸¯ç†å·¥å¤§å­¦ã€å››å·å¤§å­¦ã€å¦é—¨å¤§å­¦ã€ä¸­å—å¤§å­¦ã€ç”µå­ç§‘æŠ€å¤§å­¦ã€è¥¿åŒ—å†œæ—ç§‘æŠ€å¤§å­¦ã€ä¸Šæµ·è´¢ç»å¤§å­¦ã€è´µå·å¤§å­¦ç­‰çŸ¥åå­¦åºœç»§ç»­æ”»è¯»åšå£«å­¦ä½ã€‚å°±ä¸šå•ä½åŒ…æ‹¬é«˜æ ¡ã€ç™¾åº¦ã€çƒŸè‰å±€ã€é“¶è¡Œã€èˆªå¤©åé™¢ã€æ·±ä¿¡æœã€å†›é˜Ÿç­‰é‡è¦æœºæ„æˆ–çŸ¥åä¼ä¸šã€‚

### è¿‘æœŸæ–°é—»
- 2024-07 21çº§ç¡•å£«ç”Ÿç‹ä¸å‡¡çš„è®ºæ–‡"Joint features-Guided Linear Transformer and CNN for Efficient Image Super-Resolution"è¢«International Journal of Machine Learning and Cyberneticså½•ç”¨
- 2024-06 22çº§ç¡•å£«ç”Ÿå´äºšæ³¢çš„è®ºæ–‡["Distribution-Decouple Learning Network: An Innovative Approach for Single Image Dehazing with Spatial and Frequency Decoupling"](https://link.springer.com/article/10.1007/s00371-024-03556-3)è¢«The Visual Computerå½•ç”¨
- 2024-06 22çº§ç¡•å£«ç”Ÿ[å¢ç‰æ°](https://orcid.org/0009-0008-9786-5946)çš„è®ºæ–‡["Multi-Dimensional Manifolds Consistency Regularization for semi-supervised remote sensing semantic segmentation"](https://www.sciencedirect.com/science/article/pii/S095070512400666X)è¢«KBSå½•ç”¨
- 2024-05 ç¥è´º21çº§ç¡•å£«ç”Ÿå¼ é›ªé›ªè¢«[è´µå·å¤§å­¦](http://cs.gzu.edu.cn/2024/0511/c16270a217762/page.htm)å½•å–æ”»è¯»åšå£«å­¦ä½
- 2024-05 ç¥è´º21çº§ç¡•å£«ç”Ÿ[é¾™ä¼Ÿ](https://scholar.google.com/citations?user=CsVTBJoAAAAJ&hl=en)è¢«[ç”µå­ç§‘æŠ€å¤§å­¦](https://www.scse.uestc.edu.cn/info/1015/15961.htm)å½•å–æ”»è¯»åšå£«å­¦ä½
- 2024-05 21çº§ç¡•å£«ç”Ÿç‹ä¸å‡¡çš„è®ºæ–‡["Exploiting local detail in single image super-resolution via hypergraph convolution"](https://link.springer.com/article/10.1007/s00530-024-01355-3)è¢«Multimedia Systemså½•ç”¨
- 2024-04 ç¥è´º21çº§ç¡•å£«ç”Ÿ[å§šå’Œ](https://scholar.google.com/citations?user=c0qjMAMAAAAJ&hl=en)è¢«[å››å·å¤§å­¦](https://cs.scu.edu.cn/info/1247/18361.htm)å½•å–æ”»è¯»åšå£«å­¦ä½
- 2024-03 22çº§ç¡•å£«ç”Ÿ[é™ˆå­æ‰¬](https://scholar.google.com/citations?user=t64KgqAAAAAJ&hl=en&oi=sra)çš„è®ºæ–‡["MoCha-Stereo: Motif Channel Attention Network for Stereo Matching"](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_MoCha-Stereo_Motif_Channel_Attention_Network_for_Stereo_Matching_CVPR_2024_paper.html)è¢«CVPRå½•ç”¨
- 2024-02 22çº§ç¡•å£«ç”Ÿ[é™ˆå­æ‰¬](https://scholar.google.com/citations?user=t64KgqAAAAAJ&hl=en&oi=sra)çš„è®ºæ–‡["Feature distribution normalization network for multi-view stereo"](https://link.springer.com/article/10.1007/s00371-024-03334-1)è¢«The Visual Computerå½•ç”¨
- 2024-01 21çº§ç¡•å£«ç”Ÿç®€åæ˜¥çš„è®ºæ–‡["Dual-branch feature fusion dehazing network via multispectral channel attention"](https://link.springer.com/article/10.1007/s13042-023-02055-6)è¢«International Journal of Machine Learning and Cyberneticså½•ç”¨
- 2024-01 20çº§ç¡•å£«ç”Ÿæ¬§é˜³å©·çš„è®ºæ–‡["A multi-color and multistage collaborative network guided by refined transmission prior for underwater image enhancement"](https://link.springer.com/article/10.1007/s00371-023-03215-z)è¢«The Visual Computerå½•ç”¨
- 2024-01 ç¥è´º16çº§ç¡•å£«ç”Ÿè‚–ä¼¶è¢«å®‰å¾½å»ºç­‘å¤§å­¦è˜ç”¨ä¸ºè®²å¸ˆ
- ......æ›´å¤šä¿¡æ¯è¯¦è§[å¼ æ°¸å†›è€å¸ˆä¸»é¡µ](http://cs.gzu.edu.cn/2021/1210/c17588a163831/page.htm)


æœ€åæ›´æ–°æ—¶é—´ï¼š2024å¹´7æœˆ3æ—¥

<!--

**Here are some ideas to get you started:**

ğŸ™‹â€â™€ï¸ A short introduction - what is your organization all about?
ğŸŒˆ Contribution guidelines - how can the community get involved?
ğŸ‘©â€ğŸ’» Useful resources - where can the community find your docs? Is there anything else the community should know?
ğŸ¿ Fun facts - what does your team eat for breakfast?
ğŸ§™ Remember, you can do mighty things with the power of [Markdown](https://docs.github.com/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
-->
